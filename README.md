# Teeft adapted to French language

This package cannot be used alone. [ezs](https://www.npmjs.com/package/ezs) has to be installed

## Usage

```js
import ezs from 'ezs';
import teeftfr from 'ezs-teeftfr';

ezs.use(teeftfr);

process.stdin
    .pipe(ezs('STATEMENT_NAME', { STATEMENT_PARAMETERS })
    .pipe(process.stdout);
```

## Flow

The sequence of statements is determined by the structure of the expected input.

```txt
[ "/path/to/a/directory/of/documents" ] ->

[ListFiles]
pattern = *.txt

--> [ "/path1", "path2", ... ] -->

[GetFilesContent]

--> [ { path, content }, ... ] -->

[TEEFTSentenceTokenize]

--> [ { path, sentences: [ "sentence", ... ] }, ... ] -->

[TEEFTTokenize]

--> [ { path, sentences: [ ["token", ... ], ...] }, ... ] -->

[TEEFTNaturalTag]

--> [  { path, sentences: [ [
  {
    token: "token",
    tag: [ "tag", ...]
  }, ...
 ], ... ] }, ... ]


[TEEFTExtractTerms]
nounTag = NOM
adjTag = ADJ

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length
  },
  {
    term: "multiterm",
    frequency,
    length
  }, ...
 ] }, ... ]

[TEEFTFilterTags]
tags = NOM
tags = ADJ

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length
  },
  {
    term: "multiterm",
    frequency,
    length
  }, ...
 ] }, ... ]

[TEEFTStopWords]

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length
  },
  {
    term: "multiterm",
    frequency,
    length
  }, ...
 ] }, ... ]

[TEEFTSumUpFrequencies]

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length
  },
  {
    term: "multiterm",
    frequency,
    length
  }, ...
 ] }, ... ]

[TEEFTSpecificity]
sort = true

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length,
    specificity,
  },
  {
    term: "multiterm",
    frequency,
    length,
    specificity
  }, ...
 ] }, ... ]

[TEEFTFilterMonoFreq]

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length,
    specificity,
  },
  {
    term: "multiterm",
    frequency,
    length,
    specificity
  }, ...
 ] }, ... ]

[TEEFTFilterMultiSpec]

--> [  { path, terms:  [
  {
    term: "monoterm",
    tag: [ "tag", ...],
    frequency,
    length,
    specificity,
  },
  {
    term: "multiterm",
    frequency,
    length,
    specificity
  }, ...
 ] }, ... ]

[JSONString]
wrap = false
indent = true
```

## Statements

<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

#### Table of Contents

-   [TEEFTExtractTerms](#teeftextractterms)
    -   [Parameters](#parameters)
    -   [Examples](#examples)
-   [TEEFTFilterMonoFreq](#teeftfiltermonofreq)
    -   [Parameters](#parameters-1)
-   [TEEFTFilterMultiSpec](#teeftfiltermultispec)
    -   [Parameters](#parameters-2)
-   [TEEFTFilterTags](#teeftfiltertags)
    -   [Parameters](#parameters-3)
-   [TEEFTFrToTagLem](#teeftfrtotaglem)
    -   [Parameters](#parameters-4)
    -   [Examples](#examples-1)
-   [GetFilesContent](#getfilescontent)
-   [ListFiles](#listfiles)
    -   [Parameters](#parameters-5)
-   [natural-tag](#natural-tag)
    -   [Examples](#examples-2)
-   [profile](#profile)
    -   [Parameters](#parameters-6)
-   [TEEFTSentenceTokenize](#teeftsentencetokenize)
-   [TEEFTSpecificity](#teeftspecificity)
    -   [Parameters](#parameters-7)
-   [TEEFTStopWords](#teeftstopwords)
    -   [Parameters](#parameters-8)
-   [TEEFTSumUpFrequencies](#teeftsumupfrequencies)
    -   [Parameters](#parameters-9)
-   [tokenize](#tokenize)

### TEEFTExtractTerms

-   **See: <https://github.com/istex/sisyphe/blob/master/src/worker/teeft/lib/termextractor.js>**

Take an array of objects { path, sentences: \[token, tag: ["tag"]]}
Regroup multi-terms when possible (noun + noun, adjective + noun, _etc_.),
and computes statistics (frequency, _etc_.).

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** array of documents containing sentences of tagged tokens
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;Objects>** same as data, with `term` replacing `token`, `length`, and `frequency`
-   `nounTag` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** noun tag (optional, default `'NOM'`)
-   `adjTag` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** adjective tag (optional, default `'ADJ'`)

#### Examples

```javascript
[{
   path: '/path/1',
   sentences:
   [[
     { token: 'elle', tag: ['PRO:per'] },
     { token: 'semble', tag: ['VER'] },
     { token: 'se', tag: ['PRO:per'] },
     { token: 'nourrir', tag: ['VER'] },
     {
       token: 'essentiellement',
       tag: ['ADV'],
     },
     { token: 'de', tag: ['PRE', 'ART:def'] },
     { token: 'plancton', tag: ['NOM'] },
     { token: 'frais', tag: ['ADJ'] },
     { token: 'et', tag: ['CON'] },
     { token: 'de', tag: ['PRE', 'ART:def'] },
     { token: 'hotdog', tag: ['UNK'] }
   ]]
}]
```

### TEEFTFilterMonoFreq

Filter the `data`, keeping only multiterms and frequent monoterms.

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** 
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[Object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)>** 
-   `multiLimit` **[Number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** threshold for being a multiterm (in tokens number) (optional, default `2`)
-   `minFrequency` **[Number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** minimal frequency to be taken as a frequent term (optional, default `7`)

### TEEFTFilterMultiSpec

Filter multiterms to keep only multiterms which specificity is higher than
multiterms' average specificity.

#### Parameters

-   `data` **any** 
-   `feed` **any** 

### TEEFTFilterTags

Filter the text in input, by keeping only adjectives and names

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** 
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[Object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)>** 
-   `tags` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** Tags to keep (optional, default `['ADJ','NOM']`)

### TEEFTFrToTagLem

Tokenize, tag, and lemmatize a French text

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** 
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[Object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)>** 
-   `tagTypes` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)>** tag types (optional, default `['adj','adv','art','con','nom','ono','pre','ver','pro']`)
-   `strictness` **[Boolean](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean)** When false, non-accentuated character are the same as accentuated ones (optional, default `true`)
-   `minimumLength` **[Number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** Ignore words shorter than this (optional, default `1`)
-   `doTag` **[Boolean](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean)** return tags if true (optional, default `true`)
-   `doLemmatize` **[Boolean](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean)** return lems if true (optional, default `true`)

#### Examples

```javascript
from(['Elle semble se nourrir essentiellement de plancton, et de hotdog.'])
.pipe(ezs('TEEFTFrToTagLem', { doLemmatize: false }))
```

```javascript
[ { id: 0, token: 'elle', tag: [ 'PRO:per' ] },
{ id: 1, token: 'semble', tag: [ 'VER' ] },
{ id: 2, token: 'se', tag: [ 'PRO:per' ] },
{ id: 3, token: 'nourrir', tag: [ 'VER' ] },
{ id: 4, token: 'essentiellement', tag: [ 'ADV' ] },
{ id: 5, token: 'de', tag: [ 'PRE', 'NOM', 'ART:def' ] },
{ id: 6, token: 'plancton', tag: [ 'NOM' ] },
{ id: 7, token: 'et', tag: [ 'CON' ] },
{ id: 8, token: 'de', tag: [ 'PRE', 'NOM', 'ART:def' ] },
{ id: 9, token: 'hotdog', tag: [ 'UNK' ] } ]
```

### GetFilesContent

Take an array of file paths as input, and returns a list of
objects containing the `path`, and the `content` of each file.

### ListFiles

Take an array of directory paths as input, a pattern, and returns a list of
file paths matching the pattern in the directories from the input.

#### Parameters

-   `pattern` **[String](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** pattern for files (ex: "\*.txt") (optional, default `"*"`)

### natural-tag

POS Tagger from natural

French pos tagging using natural (and LEFFF resources)

Take an array of documents (objects: { path, sentences: \[\[]] })

Yield an array of documents (objects: {
     path, sentences: \[
         \[{
             token: "token",
             tag: [ "tag", ... ]
         },
         ...]
     ]
})

#### Examples

```javascript
[{
     path: "/path/1",
     sentences: [{ "token": "dans",      "tag": ["prep"] },
                 { "token": "le",        "tag": ["det"]  },
                 { "token": "cadre",     "tag": ["nc"] },
                 { "token": "du",        "tag": ["det"] },
                 { "token": "programme", "tag": ["nc"] }
                 },
     ]
 }]
```

### profile

Profile the time a statement takes to execute.

You have to place one to initialize, and a second to display the time it
takes.

#### Parameters

-   `data` **any** 
-   `feed` **any** 

### TEEFTSentenceTokenize

Segment the data into an array of documents (objects { path, content }).

Yield an array of documents (objects { path, sentences: \[]})

### TEEFTSpecificity

Take documents (with a `path`, an array of `terms`, each term being an object
{ term, frequency, length[, tag] })

Process objects containing frequency, add a specificity to each object, and
remove all object with a specificity below average specificity (except when
`filter` is `false`).

Can also sort the objects according to their specificity, when `sort` is
`true`.

#### Parameters

-   `data` **any** 
-   `feed` **any** 
-   `weightedDictionary` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** name of the weigthed dictionary (optional, default `"Ress_Frantext"`)
-   `filter` **[Boolean](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean)** filter below average specificity (optional, default `true`)
-   `sort` **[Boolean](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean)** sort objects according to their specificity (optional, default `false`)

### TEEFTStopWords

Filter the text in input, by removing stopwords in token

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** 
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[Object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)>** 
-   `stopwords` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** name of the stopwords file to use (optional, default `'StopwFrench'`)

### TEEFTSumUpFrequencies

Sums up the frequencies of identical lemmas from different chunks.

#### Parameters

-   `data` **[Stream](https://nodejs.org/api/stream.html)** 
-   `feed` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[Object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)>** 

### tokenize

-   **See: <http://yomguithereal.github.io/talisman/tokenizers/words>**

Extract tokens from an array of documents (objects { path, sentences: \[] }).

Yields an array of documents (objects: { path, sentences: \[\[]] })
